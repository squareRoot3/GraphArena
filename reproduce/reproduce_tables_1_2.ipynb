{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from tasks import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "difficulty = 'hard'  # easy: small graphs; hard: large graphs\n",
    "path = '../results/'+difficulty\n",
    "files = os.listdir(path)\n",
    "merged_responses = {}\n",
    "problem_num = 500\n",
    "dataset_loc = '../dataset'\n",
    "\n",
    "for f in files:\n",
    "    if len(f.split('_')) < 2:\n",
    "        continue\n",
    "    llm, task = f.split('_')[0], f.split('_')[1]\n",
    "    with open(f'{path}/{f}', 'r') as file:\n",
    "        response_dict = json.load(file)\n",
    "    for i in range(0, problem_num):\n",
    "        if task not in merged_responses:\n",
    "            merged_responses[task] = defaultdict(dict)\n",
    "        merged_responses[task][i][llm] = response_dict[str(i)][llm]\n",
    "task_list = list(merged_responses.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid literal for int() with base 10: ''\n",
      "invalid literal for int() with base 10: ''\n"
     ]
    }
   ],
   "source": [
    "# The scoring process may take a few minutes.\n",
    "# Refer to the following lines if want to evaluate on specific tasks and models.\n",
    "# task_list = ['Connected','Diameter','Distance','Neighbor']\n",
    "# model_list = 'gpt4,gpt4mini,claude,glm,llama,llama8b,deepseek,qwen72b,mixtral,gemma'.split(',')\n",
    "\n",
    "score = {}\n",
    "for task_name in task_list:\n",
    "    task= globals()[task_name + '_Task'](dataset_loc)\n",
    "    task.load_dataset(difficulty)\n",
    "    score[task_name] = defaultdict(dict)\n",
    "    for i in range(0, problem_num):\n",
    "        score[task_name][i]['gt'] = task.problem_set[i]['exact_answer']\n",
    "        if score[task_name][i]['gt'] is None:\n",
    "            score[task_name][i]['gt'] = task.problem_set[i]['approx_answer']\n",
    "        for llm in merged_responses[task_name][i].keys():\n",
    "            if llm == 'problem':\n",
    "                continue\n",
    "            r = merged_responses[task_name][i][llm]\n",
    "            if r is None:\n",
    "                r = ''\n",
    "                print(i, llm, task_name)\n",
    "            score[task_name][i][llm] = task.check_solution(i, r)\n",
    "# json.dump(score, open('score.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = defaultdict(dict)\n",
    "less_is_better = ['GED', 'TSP', 'MVC', 'Distance']\n",
    "results = []\n",
    "for task in task_list:\n",
    "    model_list = 'gpt4,gpt4mini,claude,glm,llama,llama8b,deepseek,qwen72b,mixtral,gemma,doubao,dsR1'.split(',')\n",
    "    # model_list = ['qwen2', 'qwen2SFT', 'gpt4', 'gpt4coder','deepseek','deepseekcoder']  # for Table 2 in the paper\n",
    "    for model in model_list:\n",
    "        metrics[task][model] = {'rank':[], 'feasible':[], 'MRR':[], 'hallu':[], 'acc': [],'top1':[], 'top3':[], 'len': []}\n",
    "        for i in range(0, problem_num):\n",
    "            metrics[task][model]['feasible'].append(score[task][i][model]>0)\n",
    "            metrics[task][model]['hallu'].append(score[task][i][model]==-2)\n",
    "            metrics[task][model]['len'].append(len(merged_responses[task_name][i][model]))\n",
    "            if task in ['GED', 'TSP', 'MVC']:\n",
    "                acc = 0 <= score[task][i][model] and score[task][i][model] <= score[task][i]['gt']\n",
    "            elif task in ['MCP', 'MCS', 'MIC']:\n",
    "                acc = score[task][i][model] >= score[task][i]['gt']\n",
    "            else:\n",
    "                acc = score[task][i][model] == score[task][i]['gt']\n",
    "            \n",
    "            metrics[task][model]['acc'].append(acc)\n",
    "            \n",
    "            rank = 1\n",
    "            error_knt = 0\n",
    "            for model2 in model_list:\n",
    "                if score[task][i][model2] < 0:\n",
    "                    error_knt += 1\n",
    "                if task in less_is_better:\n",
    "                    if score[task][i][model] > score[task][i][model2] and score[task][i][model2] >= 0:\n",
    "                        rank += 1\n",
    "                else:\n",
    "                    if score[task][i][model] < score[task][i][model2] and score[task][i][model2] >= 0:\n",
    "                        rank += 1\n",
    "            if score[task][i][model] < 0:\n",
    "                rank = len(model_list)\n",
    "            if error_knt == len(model_list):\n",
    "                continue\n",
    "            metrics[task][model]['rank'].append(rank)\n",
    "            metrics[task][model]['top1'].append(rank==1)\n",
    "            metrics[task][model]['top3'].append(rank<=3)\n",
    "            metrics[task][model]['MRR'].append(1/rank)\n",
    "        avg_rank = np.mean(metrics[task][model]['rank'])\n",
    "        avg_feasible = sum(metrics[task][model]['feasible']) / problem_num\n",
    "        avg_MRR = np.mean(metrics[task][model]['MRR'])\n",
    "        avg_hallu = sum(metrics[task][model]['hallu']) / problem_num\n",
    "        avg_acc = sum(metrics[task][model]['acc']) / problem_num\n",
    "        avg_top1 = np.mean(metrics[task][model]['top1'])\n",
    "        avg_top3 = np.mean(metrics[task][model]['top3'])\n",
    "        avg_len = np.mean(metrics[task][model]['len'])\n",
    "        results.append((task, model, avg_top1, avg_top3, avg_MRR, avg_feasible, avg_hallu, avg_acc, avg_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task: Connected\n",
      "Model: dsR1, Top1: 1.000, Top3: 1.000, MRR: 1.000, Feasible: 1.000, Hallucination: 0.000, Accuracy: 0.998, len: 25514.280\n",
      "Model: qwen72b, Top1: 0.284, Top3: 0.418, MRR: 0.425, Feasible: 0.718, Hallucination: 0.128, Accuracy: 0.284, len: 2415.626\n",
      "Model: gpt4mini, Top1: 0.246, Top3: 0.344, MRR: 0.374, Feasible: 0.714, Hallucination: 0.266, Accuracy: 0.246, len: 227.756\n",
      "Model: glm, Top1: 0.518, Top3: 0.602, MRR: 0.594, Feasible: 0.662, Hallucination: 0.338, Accuracy: 0.516, len: 114.640\n",
      "Model: claude, Top1: 0.518, Top3: 0.592, MRR: 0.592, Feasible: 0.658, Hallucination: 0.342, Accuracy: 0.518, len: 559.132\n",
      "Model: gpt4, Top1: 0.404, Top3: 0.474, MRR: 0.489, Feasible: 0.598, Hallucination: 0.394, Accuracy: 0.404, len: 522.306\n",
      "Model: doubao, Top1: 0.394, Top3: 0.468, MRR: 0.476, Feasible: 0.546, Hallucination: 0.454, Accuracy: 0.394, len: 199.636\n",
      "Model: llama, Top1: 0.264, Top3: 0.334, MRR: 0.367, Feasible: 0.544, Hallucination: 0.456, Accuracy: 0.264, len: 70.968\n",
      "Model: mixtral, Top1: 0.042, Top3: 0.102, MRR: 0.165, Feasible: 0.440, Hallucination: 0.536, Accuracy: 0.040, len: 159.910\n",
      "Model: deepseek, Top1: 0.154, Top3: 0.204, MRR: 0.254, Feasible: 0.348, Hallucination: 0.638, Accuracy: 0.154, len: 1190.688\n",
      "Model: llama8b, Top1: 0.022, Top3: 0.040, MRR: 0.117, Feasible: 0.162, Hallucination: 0.814, Accuracy: 0.022, len: 263.282\n",
      "Model: gemma, Top1: 0.002, Top3: 0.002, MRR: 0.085, Feasible: 0.002, Hallucination: 0.998, Accuracy: 0.002, len: 55.930\n",
      "\n",
      "Task: GED\n",
      "Model: gpt4, Top1: 0.166, Top3: 0.418, MRR: 0.369, Feasible: 0.972, Hallucination: 0.020, Accuracy: 0.038, len: 522.306\n",
      "Model: glm, Top1: 0.182, Top3: 0.456, MRR: 0.393, Feasible: 0.962, Hallucination: 0.038, Accuracy: 0.046, len: 114.640\n",
      "Model: dsR1, Top1: 0.456, Top3: 0.638, MRR: 0.592, Feasible: 0.946, Hallucination: 0.054, Accuracy: 0.104, len: 25514.280\n",
      "Model: doubao, Top1: 0.246, Top3: 0.548, MRR: 0.452, Feasible: 0.896, Hallucination: 0.092, Accuracy: 0.046, len: 199.636\n",
      "Model: deepseek, Top1: 0.178, Top3: 0.406, MRR: 0.360, Feasible: 0.846, Hallucination: 0.114, Accuracy: 0.048, len: 1190.688\n",
      "Model: claude, Top1: 0.242, Top3: 0.506, MRR: 0.426, Feasible: 0.836, Hallucination: 0.098, Accuracy: 0.046, len: 559.132\n",
      "Model: llama, Top1: 0.164, Top3: 0.332, MRR: 0.333, Feasible: 0.820, Hallucination: 0.180, Accuracy: 0.030, len: 70.968\n",
      "Model: gemma, Top1: 0.048, Top3: 0.262, MRR: 0.241, Feasible: 0.768, Hallucination: 0.232, Accuracy: 0.020, len: 55.930\n",
      "Model: gpt4mini, Top1: 0.134, Top3: 0.302, MRR: 0.283, Feasible: 0.482, Hallucination: 0.304, Accuracy: 0.034, len: 227.756\n",
      "Model: mixtral, Top1: 0.028, Top3: 0.072, MRR: 0.146, Feasible: 0.480, Hallucination: 0.214, Accuracy: 0.014, len: 159.910\n",
      "Model: qwen72b, Top1: 0.074, Top3: 0.136, MRR: 0.180, Feasible: 0.210, Hallucination: 0.076, Accuracy: 0.014, len: 2415.626\n",
      "Model: llama8b, Top1: 0.068, Top3: 0.098, MRR: 0.159, Feasible: 0.118, Hallucination: 0.878, Accuracy: 0.012, len: 263.282\n",
      "\n",
      "Task: Distance\n",
      "Model: dsR1, Top1: 0.988, Top3: 0.992, MRR: 0.991, Feasible: 0.996, Hallucination: 0.004, Accuracy: 0.986, len: 25514.280\n",
      "Model: claude, Top1: 0.800, Top3: 0.832, MRR: 0.833, Feasible: 0.894, Hallucination: 0.106, Accuracy: 0.800, len: 559.132\n",
      "Model: doubao, Top1: 0.786, Top3: 0.826, MRR: 0.823, Feasible: 0.880, Hallucination: 0.120, Accuracy: 0.786, len: 199.636\n",
      "Model: gpt4, Top1: 0.680, Top3: 0.704, MRR: 0.719, Feasible: 0.760, Hallucination: 0.224, Accuracy: 0.680, len: 522.306\n",
      "Model: glm, Top1: 0.630, Top3: 0.642, MRR: 0.668, Feasible: 0.688, Hallucination: 0.312, Accuracy: 0.630, len: 114.640\n",
      "Model: llama, Top1: 0.530, Top3: 0.548, MRR: 0.582, Feasible: 0.676, Hallucination: 0.324, Accuracy: 0.530, len: 70.968\n",
      "Model: deepseek, Top1: 0.534, Top3: 0.544, MRR: 0.583, Feasible: 0.634, Hallucination: 0.366, Accuracy: 0.534, len: 1190.688\n",
      "Model: gpt4mini, Top1: 0.426, Top3: 0.434, MRR: 0.486, Feasible: 0.574, Hallucination: 0.408, Accuracy: 0.426, len: 227.756\n",
      "Model: qwen72b, Top1: 0.522, Top3: 0.526, MRR: 0.565, Feasible: 0.550, Hallucination: 0.448, Accuracy: 0.522, len: 2415.626\n",
      "Model: mixtral, Top1: 0.282, Top3: 0.288, MRR: 0.350, Feasible: 0.416, Hallucination: 0.582, Accuracy: 0.282, len: 159.910\n",
      "Model: llama8b, Top1: 0.234, Top3: 0.236, MRR: 0.304, Feasible: 0.360, Hallucination: 0.640, Accuracy: 0.234, len: 263.282\n",
      "Model: gemma, Top1: 0.246, Top3: 0.246, MRR: 0.312, Feasible: 0.326, Hallucination: 0.674, Accuracy: 0.246, len: 55.930\n",
      "\n",
      "Task: MVC\n",
      "Model: dsR1, Top1: 0.880, Top3: 0.885, MRR: 0.892, Feasible: 0.812, Hallucination: 0.188, Accuracy: 0.802, len: 25514.280\n",
      "Model: glm, Top1: 0.126, Top3: 0.320, MRR: 0.279, Feasible: 0.432, Hallucination: 0.568, Accuracy: 0.086, len: 114.640\n",
      "Model: deepseek, Top1: 0.100, Top3: 0.224, MRR: 0.237, Feasible: 0.348, Hallucination: 0.652, Accuracy: 0.064, len: 1190.688\n",
      "Model: gpt4, Top1: 0.150, Top3: 0.214, MRR: 0.249, Feasible: 0.240, Hallucination: 0.738, Accuracy: 0.116, len: 522.306\n",
      "Model: mixtral, Top1: 0.054, Top3: 0.139, MRR: 0.174, Feasible: 0.240, Hallucination: 0.760, Accuracy: 0.036, len: 159.910\n",
      "Model: gpt4mini, Top1: 0.085, Top3: 0.148, MRR: 0.193, Feasible: 0.226, Hallucination: 0.756, Accuracy: 0.074, len: 227.756\n",
      "Model: llama8b, Top1: 0.081, Top3: 0.129, MRR: 0.185, Feasible: 0.208, Hallucination: 0.792, Accuracy: 0.064, len: 263.282\n",
      "Model: doubao, Top1: 0.115, Top3: 0.168, MRR: 0.211, Feasible: 0.180, Hallucination: 0.820, Accuracy: 0.100, len: 199.636\n",
      "Model: llama, Top1: 0.126, Top3: 0.166, MRR: 0.215, Feasible: 0.170, Hallucination: 0.830, Accuracy: 0.114, len: 70.968\n",
      "Model: gemma, Top1: 0.017, Top3: 0.044, MRR: 0.121, Feasible: 0.166, Hallucination: 0.834, Accuracy: 0.014, len: 55.930\n",
      "Model: claude, Top1: 0.087, Top3: 0.092, MRR: 0.165, Feasible: 0.086, Hallucination: 0.914, Accuracy: 0.080, len: 559.132\n",
      "Model: qwen72b, Top1: 0.011, Top3: 0.022, MRR: 0.097, Feasible: 0.022, Hallucination: 0.726, Accuracy: 0.002, len: 2415.626\n",
      "\n",
      "Task: MIS\n",
      "Model: dsR1, Top1: 0.940, Top3: 0.960, MRR: 0.954, Feasible: 0.964, Hallucination: 0.034, Accuracy: 0.750, len: 25514.280\n",
      "Model: doubao, Top1: 0.074, Top3: 0.371, MRR: 0.273, Feasible: 0.526, Hallucination: 0.474, Accuracy: 0.056, len: 199.636\n",
      "Model: llama, Top1: 0.032, Top3: 0.265, MRR: 0.215, Feasible: 0.496, Hallucination: 0.504, Accuracy: 0.026, len: 70.968\n",
      "Model: qwen72b, Top1: 0.018, Top3: 0.255, MRR: 0.208, Feasible: 0.490, Hallucination: 0.266, Accuracy: 0.008, len: 2415.626\n",
      "Model: gpt4mini, Top1: 0.018, Top3: 0.212, MRR: 0.193, Feasible: 0.484, Hallucination: 0.506, Accuracy: 0.014, len: 227.756\n",
      "Model: glm, Top1: 0.042, Top3: 0.267, MRR: 0.215, Feasible: 0.364, Hallucination: 0.628, Accuracy: 0.034, len: 114.640\n",
      "Model: mixtral, Top1: 0.010, Top3: 0.114, MRR: 0.148, Feasible: 0.362, Hallucination: 0.636, Accuracy: 0.008, len: 159.910\n",
      "Model: gpt4, Top1: 0.062, Top3: 0.230, MRR: 0.212, Feasible: 0.314, Hallucination: 0.672, Accuracy: 0.050, len: 522.306\n",
      "Model: claude, Top1: 0.098, Top3: 0.248, MRR: 0.231, Feasible: 0.266, Hallucination: 0.734, Accuracy: 0.072, len: 559.132\n",
      "Model: llama8b, Top1: 0.010, Top3: 0.060, MRR: 0.119, Feasible: 0.156, Hallucination: 0.840, Accuracy: 0.010, len: 263.282\n",
      "Model: deepseek, Top1: 0.038, Top3: 0.078, MRR: 0.137, Feasible: 0.132, Hallucination: 0.868, Accuracy: 0.032, len: 1190.688\n",
      "Model: gemma, Top1: 0.006, Top3: 0.026, MRR: 0.098, Feasible: 0.066, Hallucination: 0.934, Accuracy: 0.006, len: 55.930\n",
      "\n",
      "Task: Diameter\n",
      "Model: dsR1, Top1: 0.695, Top3: 0.715, MRR: 0.728, Feasible: 0.642, Hallucination: 0.358, Accuracy: 0.542, len: 25514.280\n",
      "Model: doubao, Top1: 0.138, Top3: 0.307, MRR: 0.278, Feasible: 0.304, Hallucination: 0.696, Accuracy: 0.086, len: 199.636\n",
      "Model: claude, Top1: 0.163, Top3: 0.303, MRR: 0.286, Feasible: 0.286, Hallucination: 0.714, Accuracy: 0.092, len: 559.132\n",
      "Model: glm, Top1: 0.105, Top3: 0.276, MRR: 0.247, Feasible: 0.284, Hallucination: 0.680, Accuracy: 0.058, len: 114.640\n",
      "Model: gpt4, Top1: 0.091, Top3: 0.238, MRR: 0.225, Feasible: 0.256, Hallucination: 0.732, Accuracy: 0.032, len: 522.306\n",
      "Model: llama, Top1: 0.071, Top3: 0.225, MRR: 0.212, Feasible: 0.252, Hallucination: 0.748, Accuracy: 0.034, len: 70.968\n",
      "Model: deepseek, Top1: 0.045, Top3: 0.180, MRR: 0.186, Feasible: 0.242, Hallucination: 0.734, Accuracy: 0.022, len: 1190.688\n",
      "Model: gpt4mini, Top1: 0.042, Top3: 0.127, MRR: 0.158, Feasible: 0.146, Hallucination: 0.834, Accuracy: 0.016, len: 227.756\n",
      "Model: mixtral, Top1: 0.013, Top3: 0.058, MRR: 0.114, Feasible: 0.078, Hallucination: 0.898, Accuracy: 0.000, len: 159.910\n",
      "Model: qwen72b, Top1: 0.007, Top3: 0.033, MRR: 0.102, Feasible: 0.062, Hallucination: 0.832, Accuracy: 0.004, len: 2415.626\n",
      "Model: llama8b, Top1: 0.016, Top3: 0.051, MRR: 0.111, Feasible: 0.060, Hallucination: 0.890, Accuracy: 0.002, len: 263.282\n",
      "Model: gemma, Top1: 0.007, Top3: 0.016, MRR: 0.093, Feasible: 0.022, Hallucination: 0.978, Accuracy: 0.004, len: 55.930\n",
      "\n",
      "Task: MCS\n",
      "Model: gemma, Top1: 0.106, Top3: 0.484, MRR: 0.337, Feasible: 0.730, Hallucination: 0.270, Accuracy: 0.000, len: 55.930\n",
      "Model: dsR1, Top1: 0.590, Top3: 0.714, MRR: 0.671, Feasible: 0.694, Hallucination: 0.306, Accuracy: 0.032, len: 25514.280\n",
      "Model: deepseek, Top1: 0.118, Top3: 0.290, MRR: 0.263, Feasible: 0.386, Hallucination: 0.606, Accuracy: 0.002, len: 1190.688\n",
      "Model: llama8b, Top1: 0.087, Top3: 0.263, MRR: 0.237, Feasible: 0.354, Hallucination: 0.646, Accuracy: 0.004, len: 263.282\n",
      "Model: llama, Top1: 0.099, Top3: 0.172, MRR: 0.205, Feasible: 0.204, Hallucination: 0.794, Accuracy: 0.004, len: 70.968\n",
      "Model: mixtral, Top1: 0.033, Top3: 0.122, MRR: 0.155, Feasible: 0.178, Hallucination: 0.786, Accuracy: 0.002, len: 159.910\n",
      "Model: gpt4mini, Top1: 0.079, Top3: 0.128, MRR: 0.177, Feasible: 0.154, Hallucination: 0.828, Accuracy: 0.012, len: 227.756\n",
      "Model: claude, Top1: 0.104, Top3: 0.122, MRR: 0.187, Feasible: 0.132, Hallucination: 0.868, Accuracy: 0.018, len: 559.132\n",
      "Model: doubao, Top1: 0.077, Top3: 0.108, MRR: 0.167, Feasible: 0.124, Hallucination: 0.876, Accuracy: 0.010, len: 199.636\n",
      "Model: qwen72b, Top1: 0.083, Top3: 0.110, MRR: 0.171, Feasible: 0.120, Hallucination: 0.872, Accuracy: 0.010, len: 2415.626\n",
      "Model: gpt4, Top1: 0.060, Top3: 0.089, MRR: 0.150, Feasible: 0.092, Hallucination: 0.816, Accuracy: 0.012, len: 522.306\n",
      "Model: glm, Top1: 0.062, Top3: 0.081, MRR: 0.149, Feasible: 0.090, Hallucination: 0.910, Accuracy: 0.014, len: 114.640\n",
      "\n",
      "Task: Neighbor\n",
      "Model: dsR1, Top1: 0.984, Top3: 0.984, MRR: 0.986, Feasible: 0.988, Hallucination: 0.008, Accuracy: 0.984, len: 25514.280\n",
      "Model: claude, Top1: 0.938, Top3: 0.946, MRR: 0.949, Feasible: 0.982, Hallucination: 0.018, Accuracy: 0.938, len: 559.132\n",
      "Model: doubao, Top1: 0.862, Top3: 0.868, MRR: 0.880, Feasible: 0.904, Hallucination: 0.090, Accuracy: 0.862, len: 199.636\n",
      "Model: qwen72b, Top1: 0.784, Top3: 0.786, MRR: 0.813, Feasible: 0.900, Hallucination: 0.044, Accuracy: 0.784, len: 2415.626\n",
      "Model: gpt4mini, Top1: 0.776, Top3: 0.782, MRR: 0.802, Feasible: 0.842, Hallucination: 0.120, Accuracy: 0.776, len: 227.756\n",
      "Model: gpt4, Top1: 0.626, Top3: 0.632, MRR: 0.672, Feasible: 0.740, Hallucination: 0.140, Accuracy: 0.626, len: 522.306\n",
      "Model: glm, Top1: 0.624, Top3: 0.628, MRR: 0.658, Feasible: 0.644, Hallucination: 0.350, Accuracy: 0.624, len: 114.640\n",
      "Model: llama, Top1: 0.434, Top3: 0.436, MRR: 0.490, Feasible: 0.500, Hallucination: 0.434, Accuracy: 0.434, len: 70.968\n",
      "Model: mixtral, Top1: 0.232, Top3: 0.234, MRR: 0.301, Feasible: 0.324, Hallucination: 0.672, Accuracy: 0.232, len: 159.910\n",
      "Model: gemma, Top1: 0.116, Top3: 0.116, MRR: 0.196, Feasible: 0.292, Hallucination: 0.708, Accuracy: 0.116, len: 55.930\n",
      "Model: deepseek, Top1: 0.278, Top3: 0.280, MRR: 0.340, Feasible: 0.290, Hallucination: 0.708, Accuracy: 0.278, len: 1190.688\n",
      "Model: llama8b, Top1: 0.118, Top3: 0.118, MRR: 0.194, Feasible: 0.174, Hallucination: 0.784, Accuracy: 0.118, len: 263.282\n",
      "\n",
      "Task: MCP\n",
      "Model: dsR1, Top1: 0.940, Top3: 0.968, MRR: 0.956, Feasible: 0.970, Hallucination: 0.030, Accuracy: 0.806, len: 25514.280\n",
      "Model: claude, Top1: 0.220, Top3: 0.619, MRR: 0.447, Feasible: 0.798, Hallucination: 0.202, Accuracy: 0.190, len: 559.132\n",
      "Model: gpt4, Top1: 0.172, Top3: 0.491, MRR: 0.366, Feasible: 0.632, Hallucination: 0.358, Accuracy: 0.152, len: 522.306\n",
      "Model: glm, Top1: 0.118, Top3: 0.251, MRR: 0.244, Feasible: 0.326, Hallucination: 0.662, Accuracy: 0.106, len: 114.640\n",
      "Model: doubao, Top1: 0.106, Top3: 0.234, MRR: 0.236, Feasible: 0.320, Hallucination: 0.676, Accuracy: 0.096, len: 199.636\n",
      "Model: gpt4mini, Top1: 0.076, Top3: 0.194, MRR: 0.201, Feasible: 0.260, Hallucination: 0.726, Accuracy: 0.064, len: 227.756\n",
      "Model: llama, Top1: 0.114, Top3: 0.152, MRR: 0.204, Feasible: 0.164, Hallucination: 0.836, Accuracy: 0.106, len: 70.968\n",
      "Model: qwen72b, Top1: 0.014, Top3: 0.056, MRR: 0.117, Feasible: 0.124, Hallucination: 0.372, Accuracy: 0.008, len: 2415.626\n",
      "Model: mixtral, Top1: 0.036, Top3: 0.070, MRR: 0.131, Feasible: 0.110, Hallucination: 0.888, Accuracy: 0.034, len: 159.910\n",
      "Model: gemma, Top1: 0.016, Top3: 0.046, MRR: 0.112, Feasible: 0.078, Hallucination: 0.922, Accuracy: 0.016, len: 55.930\n",
      "Model: llama8b, Top1: 0.022, Top3: 0.054, MRR: 0.118, Feasible: 0.074, Hallucination: 0.916, Accuracy: 0.022, len: 263.282\n",
      "Model: deepseek, Top1: 0.036, Top3: 0.046, MRR: 0.121, Feasible: 0.052, Hallucination: 0.948, Accuracy: 0.032, len: 1190.688\n",
      "\n",
      "Task: TSP\n",
      "Model: dsR1, Top1: 0.548, Top3: 0.920, MRR: 0.734, Feasible: 1.000, Hallucination: 0.000, Accuracy: 0.094, len: 25514.280\n",
      "Model: claude, Top1: 0.304, Top3: 0.800, MRR: 0.561, Feasible: 0.996, Hallucination: 0.004, Accuracy: 0.028, len: 559.132\n",
      "Model: gpt4, Top1: 0.116, Top3: 0.540, MRR: 0.385, Feasible: 0.956, Hallucination: 0.014, Accuracy: 0.008, len: 522.306\n",
      "Model: doubao, Top1: 0.104, Top3: 0.490, MRR: 0.359, Feasible: 0.912, Hallucination: 0.020, Accuracy: 0.006, len: 199.636\n",
      "Model: glm, Top1: 0.022, Top3: 0.126, MRR: 0.210, Feasible: 0.858, Hallucination: 0.140, Accuracy: 0.000, len: 114.640\n",
      "Model: llama, Top1: 0.002, Top3: 0.036, MRR: 0.156, Feasible: 0.846, Hallucination: 0.154, Accuracy: 0.000, len: 70.968\n",
      "Model: gpt4mini, Top1: 0.000, Top3: 0.010, MRR: 0.136, Feasible: 0.778, Hallucination: 0.204, Accuracy: 0.000, len: 227.756\n",
      "Model: deepseek, Top1: 0.014, Top3: 0.078, MRR: 0.171, Feasible: 0.690, Hallucination: 0.300, Accuracy: 0.006, len: 1190.688\n",
      "Model: llama8b, Top1: 0.000, Top3: 0.000, MRR: 0.103, Feasible: 0.534, Hallucination: 0.458, Accuracy: 0.000, len: 263.282\n",
      "Model: mixtral, Top1: 0.000, Top3: 0.000, MRR: 0.097, Feasible: 0.394, Hallucination: 0.594, Accuracy: 0.000, len: 159.910\n",
      "Model: qwen72b, Top1: 0.004, Top3: 0.026, MRR: 0.119, Feasible: 0.316, Hallucination: 0.216, Accuracy: 0.000, len: 2415.626\n",
      "Model: gemma, Top1: 0.000, Top3: 0.000, MRR: 0.085, Feasible: 0.062, Hallucination: 0.934, Accuracy: 0.000, len: 55.930\n",
      "\n",
      "Average Performance Across All Tasks:\n",
      "Model: dsR1, Average MRR: 0.850, Average Top1: 0.802, Feasible: 0.901, Hallucination: 0.098, Accuracy: 0.610, len: 25514.280\n",
      "Model: claude, Average MRR: 0.468, Average Top1: 0.347, Feasible: 0.593, Hallucination: 0.400, Accuracy: 0.278, len: 559.132\n",
      "Model: doubao, Average MRR: 0.416, Average Top1: 0.290, Feasible: 0.559, Hallucination: 0.432, Accuracy: 0.244, len: 199.636\n",
      "Model: gpt4, Average MRR: 0.384, Average Top1: 0.253, Feasible: 0.556, Hallucination: 0.411, Accuracy: 0.212, len: 522.306\n",
      "Model: glm, Average MRR: 0.366, Average Top1: 0.243, Feasible: 0.531, Hallucination: 0.463, Accuracy: 0.211, len: 114.640\n",
      "Model: gpt4mini, Average MRR: 0.300, Average Top1: 0.188, Feasible: 0.466, Hallucination: 0.495, Accuracy: 0.166, len: 227.756\n",
      "Model: llama, Average MRR: 0.298, Average Top1: 0.184, Feasible: 0.467, Hallucination: 0.526, Accuracy: 0.154, len: 70.968\n",
      "Model: qwen72b, Average MRR: 0.280, Average Top1: 0.180, Feasible: 0.351, Hallucination: 0.398, Accuracy: 0.164, len: 2415.626\n",
      "Model: deepseek, Average MRR: 0.265, Average Top1: 0.149, Feasible: 0.397, Hallucination: 0.593, Accuracy: 0.117, len: 1190.688\n",
      "Model: mixtral, Average MRR: 0.178, Average Top1: 0.073, Feasible: 0.302, Hallucination: 0.657, Accuracy: 0.065, len: 159.910\n",
      "Model: gemma, Average MRR: 0.168, Average Top1: 0.056, Feasible: 0.251, Hallucination: 0.748, Accuracy: 0.042, len: 55.930\n",
      "Model: llama8b, Average MRR: 0.165, Average Top1: 0.066, Feasible: 0.220, Hallucination: 0.766, Accuracy: 0.049, len: 263.282\n"
     ]
    }
   ],
   "source": [
    "# Sorting the results by MRR for each task\n",
    "sorted_results = defaultdict(list)\n",
    "\n",
    "for task in task_list:\n",
    "    task_results = [result for result in results if result[0] == task]\n",
    "    sorted_results[task] = sorted(task_results, key=lambda x: x[5], reverse=True)  # Sort by MRR\n",
    "\n",
    "# Print sorted results for each task\n",
    "for task, task_results in sorted_results.items():\n",
    "    print(f\"\\nTask: {task}\")\n",
    "    for result in task_results:\n",
    "        print(f\"Model: {result[1]}, Top1: {result[2]:.3f}, Top3: {result[3]:.3f}, MRR: {result[4]:.3f}, Feasible: {result[5]:.3f}, Hallucination: {result[6]:.3f}, Accuracy: {result[7]:.3f}, len: {result[8]:.3f}\")\n",
    "\n",
    "# Calculate average MRR performance across all tasks for each model\n",
    "model_metrics = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "# Aggregate metrics for each model across tasks\n",
    "for result in results:\n",
    "    task, model, avg_top1, avg_top3, avg_MRR, avg_feasible, avg_hallu, avg_acc, avg_len = result\n",
    "    model_metrics[model]['MRR'].append(avg_MRR)\n",
    "    model_metrics[model]['top1'].append(avg_top1)\n",
    "    model_metrics[model]['top3'].append(avg_top3)\n",
    "    model_metrics[model]['feasible'].append(avg_feasible)\n",
    "    model_metrics[model]['hallu'].append(avg_hallu)\n",
    "    model_metrics[model]['acc'].append(avg_acc)\n",
    "    model_metrics[model]['len'].append(avg_len)\n",
    "    \n",
    "# Compute average metrics for each model and sort models by their average MRR\n",
    "average_metrics_performance = {model: {metric: sum(values) / len(values) for metric, values in metrics.items()} for model, metrics in model_metrics.items()}\n",
    "sorted_average_metrics = sorted(average_metrics_performance.items(), key=lambda x: x[1]['MRR'], reverse=True)\n",
    "\n",
    "# Print the sorted average metrics for each model\n",
    "print(\"\\nAverage Performance Across All Tasks:\")\n",
    "for model, metrics in sorted_average_metrics:\n",
    "    print(f\"Model: {model}, Average MRR: {metrics['MRR']:.3f}, Average Top1: {metrics['top1']:.3f}, Feasible: {metrics['feasible']:.3f}, Hallucination: {metrics['hallu']:.3f}, Accuracy: {metrics['acc']:.3f}, len: {metrics['len']:.3f}\")\n",
    "\n",
    "# average for P tasks and NP tasks separately\n",
    "P_tasks = ['Connected','Diameter','Distance','Neighbor']\n",
    "NP_tasks = ['GED','TSP','MCP','MCS','MIC','MVC']\n",
    "P_results = []\n",
    "NP_results = []\n",
    "for result in results:\n",
    "    task, model, avg_top1, avg_top3, avg_MRR, avg_feasible, avg_hallu, avg_acc, avg_len = result\n",
    "    if task in P_tasks:\n",
    "        P_results.append(result)\n",
    "    else:\n",
    "        NP_results.append(result)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "difficulty: hard, large graphs\n",
      "\n",
      "Average Performance for P Tasks:\n",
      "Model: dsR1, Average MRR: 0.926, Average Top1: 0.917, Average Top3: 0.923, Feasible: 0.906, Hallucination: 0.092, Accuracy: 0.877\n",
      "Model: claude, Average MRR: 0.665, Average Top1: 0.605, Average Top3: 0.668, Feasible: 0.705, Hallucination: 0.295, Accuracy: 0.587\n",
      "Model: doubao, Average MRR: 0.614, Average Top1: 0.545, Average Top3: 0.617, Feasible: 0.659, Hallucination: 0.340, Accuracy: 0.532\n",
      "Model: glm, Average MRR: 0.542, Average Top1: 0.469, Average Top3: 0.537, Feasible: 0.570, Hallucination: 0.420, Accuracy: 0.457\n",
      "Model: gpt4, Average MRR: 0.526, Average Top1: 0.450, Average Top3: 0.512, Feasible: 0.589, Hallucination: 0.373, Accuracy: 0.435\n",
      "Model: qwen72b, Average MRR: 0.476, Average Top1: 0.399, Average Top3: 0.441, Feasible: 0.557, Hallucination: 0.363, Accuracy: 0.399\n",
      "Model: gpt4mini, Average MRR: 0.455, Average Top1: 0.373, Average Top3: 0.422, Feasible: 0.569, Hallucination: 0.407, Accuracy: 0.366\n",
      "Model: llama, Average MRR: 0.413, Average Top1: 0.325, Average Top3: 0.386, Feasible: 0.493, Hallucination: 0.490, Accuracy: 0.316\n",
      "Model: deepseek, Average MRR: 0.341, Average Top1: 0.253, Average Top3: 0.302, Feasible: 0.379, Hallucination: 0.611, Accuracy: 0.247\n",
      "Model: mixtral, Average MRR: 0.232, Average Top1: 0.142, Average Top3: 0.170, Feasible: 0.315, Hallucination: 0.672, Accuracy: 0.138\n",
      "Model: llama8b, Average MRR: 0.182, Average Top1: 0.097, Average Top3: 0.111, Feasible: 0.189, Hallucination: 0.782, Accuracy: 0.094\n",
      "Model: gemma, Average MRR: 0.172, Average Top1: 0.093, Average Top3: 0.095, Feasible: 0.161, Hallucination: 0.840, Accuracy: 0.092\n",
      "\n",
      "Average Performance for NP Tasks:\n",
      "Model: dsR1, Average MRR: 0.800, Average Top1: 0.726, Average Top3: 0.847, Feasible: 0.898, Hallucination: 0.102, Accuracy: 0.431\n",
      "Model: claude, Average MRR: 0.336, Average Top1: 0.176, Average Top3: 0.398, Feasible: 0.519, Hallucination: 0.470, Accuracy: 0.072\n",
      "Model: gpt4, Average MRR: 0.288, Average Top1: 0.121, Average Top3: 0.330, Feasible: 0.534, Hallucination: 0.436, Accuracy: 0.063\n",
      "Model: doubao, Average MRR: 0.283, Average Top1: 0.120, Average Top3: 0.320, Feasible: 0.493, Hallucination: 0.493, Accuracy: 0.052\n",
      "Model: glm, Average MRR: 0.248, Average Top1: 0.092, Average Top3: 0.250, Feasible: 0.505, Hallucination: 0.491, Accuracy: 0.048\n",
      "Model: llama, Average MRR: 0.221, Average Top1: 0.090, Average Top3: 0.187, Feasible: 0.450, Hallucination: 0.550, Accuracy: 0.047\n",
      "Model: deepseek, Average MRR: 0.215, Average Top1: 0.081, Average Top3: 0.187, Feasible: 0.409, Hallucination: 0.581, Accuracy: 0.031\n",
      "Model: gpt4mini, Average MRR: 0.197, Average Top1: 0.065, Average Top3: 0.166, Feasible: 0.397, Hallucination: 0.554, Accuracy: 0.033\n",
      "Model: gemma, Average MRR: 0.165, Average Top1: 0.032, Average Top3: 0.144, Feasible: 0.312, Hallucination: 0.688, Accuracy: 0.009\n",
      "Model: llama8b, Average MRR: 0.153, Average Top1: 0.045, Average Top3: 0.101, Feasible: 0.241, Hallucination: 0.755, Accuracy: 0.019\n",
      "Model: qwen72b, Average MRR: 0.149, Average Top1: 0.034, Average Top3: 0.101, Feasible: 0.214, Hallucination: 0.421, Accuracy: 0.007\n",
      "Model: mixtral, Average MRR: 0.142, Average Top1: 0.027, Average Top3: 0.086, Feasible: 0.294, Hallucination: 0.646, Accuracy: 0.016\n"
     ]
    }
   ],
   "source": [
    "# Calculate average metrics for P tasks and NP tasks separately\n",
    "P_metrics = defaultdict(lambda: defaultdict(list))\n",
    "NP_metrics = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "# Aggregate metrics for P and NP tasks\n",
    "for result in P_results:\n",
    "    task, model, avg_top1, avg_top3, avg_MRR, avg_feasible, avg_hallu, avg_acc, avg_len = result\n",
    "    P_metrics[model]['MRR'].append(avg_MRR)\n",
    "    P_metrics[model]['top1'].append(avg_top1)\n",
    "    P_metrics[model]['top3'].append(avg_top3)\n",
    "    P_metrics[model]['feasible'].append(avg_feasible)\n",
    "    P_metrics[model]['hallu'].append(avg_hallu)\n",
    "    P_metrics[model]['acc'].append(avg_acc)\n",
    "    P_metrics[model]['len'].append(avg_len)\n",
    "\n",
    "for result in NP_results:\n",
    "    task, model, avg_top1, avg_top3, avg_MRR, avg_feasible, avg_hallu, avg_acc, avg_len = result\n",
    "    NP_metrics[model]['MRR'].append(avg_MRR)\n",
    "    NP_metrics[model]['top1'].append(avg_top1)\n",
    "    NP_metrics[model]['top3'].append(avg_top3)\n",
    "    NP_metrics[model]['feasible'].append(avg_feasible)\n",
    "    NP_metrics[model]['hallu'].append(avg_hallu)\n",
    "    NP_metrics[model]['acc'].append(avg_acc)\n",
    "    NP_metrics[model]['len'].append(avg_len)\n",
    "\n",
    "# Compute average metrics for P and NP tasks\n",
    "average_P_metrics = {model: {metric: sum(values) / len(values) for metric, values in metrics.items()} for model, metrics in P_metrics.items()}\n",
    "average_NP_metrics = {model: {metric: sum(values) / len(values) for metric, values in metrics.items()} for model, metrics in NP_metrics.items()}\n",
    "\n",
    "# Sort models by their average MRR for P and NP tasks\n",
    "sorted_P_metrics = sorted(average_P_metrics.items(), key=lambda x: x[1]['MRR'], reverse=True)\n",
    "sorted_NP_metrics = sorted(average_NP_metrics.items(), key=lambda x: x[1]['MRR'], reverse=True)\n",
    "\n",
    "\n",
    "print(f\"difficulty: {difficulty}, {'small' if difficulty == 'easy' else 'large'} graphs\")\n",
    "# Print the sorted average metrics for P tasks\n",
    "print(\"\\nAverage Performance for P Tasks:\")\n",
    "for model, metrics in sorted_P_metrics:\n",
    "    print(f\"Model: {model}, Average MRR: {metrics['MRR']:.3f}, Average Top1: {metrics['top1']:.3f}, Average Top3: {metrics['top3']:.3f}, Feasible: {metrics['feasible']:.3f}, Hallucination: {metrics['hallu']:.3f}, Accuracy: {metrics['acc']:.3f}\")\n",
    "\n",
    "# Print the sorted average metrics for NP tasks\n",
    "print(\"\\nAverage Performance for NP Tasks:\")\n",
    "for model, metrics in sorted_NP_metrics:\n",
    "    print(f\"Model: {model}, Average MRR: {metrics['MRR']:.3f}, Average Top1: {metrics['top1']:.3f}, Average Top3: {metrics['top3']:.3f}, Feasible: {metrics['feasible']:.3f}, Hallucination: {metrics['hallu']:.3f}, Accuracy: {metrics['acc']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difficulty: easy, small graphs\n",
    "\n",
    "# Average Performance for P Tasks:\n",
    "# Model: dsR1, Average MRR: 0.982, Average Top1: 0.979, Average Top3: 0.981, Feasible: 0.984, Hallucination: 0.014, Accuracy: 0.976\n",
    "# Model: claude, Average MRR: 0.848, Average Top1: 0.824, Average Top3: 0.842, Feasible: 0.865, Hallucination: 0.134, Accuracy: 0.822\n",
    "# Model: doubao, Average MRR: 0.821, Average Top1: 0.794, Average Top3: 0.810, Feasible: 0.848, Hallucination: 0.150, Accuracy: 0.792\n",
    "# Model: gpt4, Average MRR: 0.805, Average Top1: 0.772, Average Top3: 0.795, Feasible: 0.846, Hallucination: 0.134, Accuracy: 0.769\n",
    "# Model: glm, Average MRR: 0.764, Average Top1: 0.730, Average Top3: 0.750, Feasible: 0.788, Hallucination: 0.186, Accuracy: 0.727\n",
    "# Model: gpt4mini, Average MRR: 0.733, Average Top1: 0.692, Average Top3: 0.713, Feasible: 0.828, Hallucination: 0.161, Accuracy: 0.689\n",
    "# Model: llama, Average MRR: 0.660, Average Top1: 0.615, Average Top3: 0.634, Feasible: 0.719, Hallucination: 0.273, Accuracy: 0.612\n",
    "# Model: qwen72b, Average MRR: 0.643, Average Top1: 0.590, Average Top3: 0.604, Feasible: 0.748, Hallucination: 0.117, Accuracy: 0.590\n",
    "# Model: deepseek, Average MRR: 0.572, Average Top1: 0.515, Average Top3: 0.537, Feasible: 0.642, Hallucination: 0.350, Accuracy: 0.514\n",
    "# Model: mixtral, Average MRR: 0.440, Average Top1: 0.379, Average Top3: 0.386, Feasible: 0.513, Hallucination: 0.464, Accuracy: 0.378\n",
    "# Model: llama8b, Average MRR: 0.355, Average Top1: 0.286, Average Top3: 0.294, Feasible: 0.445, Hallucination: 0.539, Accuracy: 0.285\n",
    "# Model: gemma, Average MRR: 0.321, Average Top1: 0.252, Average Top3: 0.257, Feasible: 0.386, Hallucination: 0.614, Accuracy: 0.252\n",
    "\n",
    "# Average Performance for NP Tasks:\n",
    "# Model: dsR1, Average MRR: 0.961, Average Top1: 0.949, Average Top3: 0.968, Feasible: 0.972, Hallucination: 0.027, Accuracy: 0.877\n",
    "# Model: claude, Average MRR: 0.596, Average Top1: 0.507, Average Top3: 0.606, Feasible: 0.744, Hallucination: 0.255, Accuracy: 0.478\n",
    "# Model: doubao, Average MRR: 0.592, Average Top1: 0.495, Average Top3: 0.614, Feasible: 0.777, Hallucination: 0.217, Accuracy: 0.467\n",
    "# Model: gpt4, Average MRR: 0.587, Average Top1: 0.495, Average Top3: 0.595, Feasible: 0.770, Hallucination: 0.202, Accuracy: 0.473\n",
    "# Model: glm, Average MRR: 0.536, Average Top1: 0.437, Average Top3: 0.533, Feasible: 0.788, Hallucination: 0.204, Accuracy: 0.413\n",
    "# Model: gpt4mini, Average MRR: 0.510, Average Top1: 0.414, Average Top3: 0.502, Feasible: 0.724, Hallucination: 0.255, Accuracy: 0.392\n",
    "# Model: llama, Average MRR: 0.487, Average Top1: 0.391, Average Top3: 0.463, Feasible: 0.753, Hallucination: 0.245, Accuracy: 0.368\n",
    "# Model: deepseek, Average MRR: 0.457, Average Top1: 0.351, Average Top3: 0.439, Feasible: 0.741, Hallucination: 0.245, Accuracy: 0.337\n",
    "# Model: qwen72b, Average MRR: 0.334, Average Top1: 0.226, Average Top3: 0.295, Feasible: 0.651, Hallucination: 0.270, Accuracy: 0.206\n",
    "# Model: llama8b, Average MRR: 0.305, Average Top1: 0.208, Average Top3: 0.254, Feasible: 0.579, Hallucination: 0.417, Accuracy: 0.202\n",
    "# Model: mixtral, Average MRR: 0.263, Average Top1: 0.162, Average Top3: 0.201, Feasible: 0.593, Hallucination: 0.374, Accuracy: 0.156\n",
    "# Model: gemma, Average MRR: 0.244, Average Top1: 0.135, Average Top3: 0.185, Feasible: 0.571, Hallucination: 0.426, Accuracy: 0.129\n",
    "\n",
    "# difficulty: hard, large graphs\n",
    "\n",
    "# Average Performance for P Tasks:\n",
    "# Model: dsR1, Average MRR: 0.926, Average Top1: 0.917, Average Top3: 0.923, Feasible: 0.906, Hallucination: 0.092, Accuracy: 0.877\n",
    "# Model: claude, Average MRR: 0.665, Average Top1: 0.605, Average Top3: 0.668, Feasible: 0.705, Hallucination: 0.295, Accuracy: 0.587\n",
    "# Model: doubao, Average MRR: 0.614, Average Top1: 0.545, Average Top3: 0.617, Feasible: 0.659, Hallucination: 0.340, Accuracy: 0.532\n",
    "# Model: glm, Average MRR: 0.542, Average Top1: 0.469, Average Top3: 0.537, Feasible: 0.570, Hallucination: 0.420, Accuracy: 0.457\n",
    "# Model: gpt4, Average MRR: 0.526, Average Top1: 0.450, Average Top3: 0.512, Feasible: 0.589, Hallucination: 0.373, Accuracy: 0.435\n",
    "# Model: qwen72b, Average MRR: 0.476, Average Top1: 0.399, Average Top3: 0.441, Feasible: 0.557, Hallucination: 0.363, Accuracy: 0.399\n",
    "# Model: gpt4mini, Average MRR: 0.455, Average Top1: 0.373, Average Top3: 0.422, Feasible: 0.569, Hallucination: 0.407, Accuracy: 0.366\n",
    "# Model: llama, Average MRR: 0.413, Average Top1: 0.325, Average Top3: 0.386, Feasible: 0.493, Hallucination: 0.490, Accuracy: 0.316\n",
    "# Model: deepseek, Average MRR: 0.341, Average Top1: 0.253, Average Top3: 0.302, Feasible: 0.379, Hallucination: 0.611, Accuracy: 0.247\n",
    "# Model: mixtral, Average MRR: 0.232, Average Top1: 0.142, Average Top3: 0.170, Feasible: 0.315, Hallucination: 0.672, Accuracy: 0.138\n",
    "# Model: llama8b, Average MRR: 0.182, Average Top1: 0.097, Average Top3: 0.111, Feasible: 0.189, Hallucination: 0.782, Accuracy: 0.094\n",
    "# Model: gemma, Average MRR: 0.172, Average Top1: 0.093, Average Top3: 0.095, Feasible: 0.161, Hallucination: 0.840, Accuracy: 0.092\n",
    "\n",
    "# Average Performance for NP Tasks:\n",
    "# Model: dsR1, Average MRR: 0.800, Average Top1: 0.726, Average Top3: 0.847, Feasible: 0.898, Hallucination: 0.102, Accuracy: 0.431\n",
    "# Model: claude, Average MRR: 0.336, Average Top1: 0.176, Average Top3: 0.398, Feasible: 0.519, Hallucination: 0.470, Accuracy: 0.072\n",
    "# Model: gpt4, Average MRR: 0.288, Average Top1: 0.121, Average Top3: 0.330, Feasible: 0.534, Hallucination: 0.436, Accuracy: 0.063\n",
    "# Model: doubao, Average MRR: 0.283, Average Top1: 0.120, Average Top3: 0.320, Feasible: 0.493, Hallucination: 0.493, Accuracy: 0.052\n",
    "# Model: glm, Average MRR: 0.248, Average Top1: 0.092, Average Top3: 0.250, Feasible: 0.505, Hallucination: 0.491, Accuracy: 0.048\n",
    "# Model: llama, Average MRR: 0.221, Average Top1: 0.090, Average Top3: 0.187, Feasible: 0.450, Hallucination: 0.550, Accuracy: 0.047\n",
    "# Model: deepseek, Average MRR: 0.215, Average Top1: 0.081, Average Top3: 0.187, Feasible: 0.409, Hallucination: 0.581, Accuracy: 0.031\n",
    "# Model: gpt4mini, Average MRR: 0.197, Average Top1: 0.065, Average Top3: 0.166, Feasible: 0.397, Hallucination: 0.554, Accuracy: 0.033\n",
    "# Model: gemma, Average MRR: 0.165, Average Top1: 0.032, Average Top3: 0.144, Feasible: 0.312, Hallucination: 0.688, Accuracy: 0.009\n",
    "# Model: llama8b, Average MRR: 0.153, Average Top1: 0.045, Average Top3: 0.101, Feasible: 0.241, Hallucination: 0.755, Accuracy: 0.019\n",
    "# Model: qwen72b, Average MRR: 0.149, Average Top1: 0.034, Average Top3: 0.101, Feasible: 0.214, Hallucination: 0.421, Accuracy: 0.007\n",
    "# Model: mixtral, Average MRR: 0.142, Average Top1: 0.027, Average Top3: 0.086, Feasible: 0.294, Hallucination: 0.646, Accuracy: 0.016"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
